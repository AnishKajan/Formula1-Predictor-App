import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, mean_absolute_error
from sklearn.preprocessing import LabelEncoder, StandardScaler
import numpy as np
import os
import joblib
import random
from datetime import datetime

# Create output folder for models
os.makedirs("models", exist_ok=True)
os.makedirs("logs", exist_ok=True)

def enhance_weather_features(df):
    """Add more sophisticated weather-related features"""
    
    # Temperature ranges based on circuit locations and seasons
    def get_temperature(circuit, date=None):
        temp_map = {
            'Bahrain International Circuit': random.randint(25, 35),
            'Jeddah Corniche Circuit': random.randint(28, 38),
            'Albert Park Circuit': random.randint(18, 28),
            'Suzuka Circuit': random.randint(15, 25),
            'Shanghai International Circuit': random.randint(12, 22),
            'Miami International Autodrome': random.randint(26, 35),
            'Imola': random.randint(16, 26),
            'Monaco Circuit': random.randint(18, 28),
            'Circuit de Barcelona-Catalunya': random.randint(16, 26),
            'Circuit Gilles Villeneuve': random.randint(12, 22),
            'Red Bull Ring': random.randint(14, 24),
            'Silverstone Circuit': random.randint(12, 22),
            'Hungaroring': random.randint(18, 30),
            'Circuit de Spa-Francorchamps': random.randint(10, 20),
            'Circuit Zandvoort': random.randint(12, 22),
            'Monza Circuit': random.randint(16, 26),
            'Marina Bay Street Circuit': random.randint(26, 32),
            'Baku City Circuit': random.randint(20, 30),
            'Circuit of the Americas': random.randint(18, 28),
            'Aut√≥dromo Hermanos Rodr√≠guez': random.randint(16, 24),
            'Interlagos': random.randint(18, 28),
            'Las Vegas Strip Circuit': random.randint(10, 25),
            'Losail International Circuit': random.randint(22, 32),
            'Yas Marina Circuit': random.randint(24, 32)
        }
        return temp_map.get(circuit, random.randint(15, 25))
    
    # Add enhanced weather features
    df['temperature'] = df['circuit'].apply(get_temperature)
    df['humidity'] = np.where(df['weather'] == 'Wet', 
                              np.random.uniform(80, 95, len(df)),
                              np.where(df['weather'] == 'Mixed',
                                      np.random.uniform(60, 85, len(df)),
                                      np.random.uniform(30, 70, len(df))))
    
    df['wind_speed'] = np.where(df['weather'] == 'Wet',
                               np.random.uniform(10, 20, len(df)),
                               np.where(df['weather'] == 'Mixed',
                                       np.random.uniform(5, 15, len(df)),
                                       np.random.uniform(0, 10, len(df))))
    
    df['track_temp'] = df['temperature'] + np.random.uniform(5, 25, len(df))
    
    return df

def enhance_tire_strategy(df):
    """Generate realistic tire strategies"""
    
    def get_strategy(weather, circuit):
        street_circuits = ['Monaco Circuit', 'Marina Bay Street Circuit', 'Baku City Circuit', 'Jeddah Corniche Circuit']
        
        if weather == "Wet":
            return random.choice([
                "Full Wet ‚Üí Intermediate ‚Üí Medium",
                "Intermediate ‚Üí Full Wet",
                "Full Wet ‚Üí Medium",
                "Intermediate ‚Üí Soft"
            ])
        elif weather == "Mixed":
            return random.choice([
                "Intermediate ‚Üí Medium ‚Üí Soft",
                "Soft ‚Üí Intermediate ‚Üí Hard",
                "Medium ‚Üí Intermediate ‚Üí Soft"
            ])
        else:  # Dry conditions
            if circuit in street_circuits:
                return random.choice([
                    "Medium ‚Üí Hard",
                    "Soft ‚Üí Medium ‚Üí Hard",
                    "Hard ‚Üí Medium",
                    "Soft ‚Üí Hard"
                ])
            else:
                return random.choice([
                    "Soft ‚Üí Medium",
                    "Medium ‚Üí Hard",
                    "Soft ‚Üí Hard",
                    "Medium ‚Üí Medium"
                ])
    
    df['tire_strategy'] = df.apply(lambda row: get_strategy(row['weather'], row['circuit']), axis=1)
    return df

def add_driver_performance_features(df):
    """Add realistic driver performance metrics"""
    
    # Modern F1 driver experience mapping
    driver_experience = {
        'Lewis Hamilton': 19,           # 2007‚Äì2025
        'Fernando Alonso': 21,          # 2001‚Äì2018, 2021‚Äì2025 (break: 2019‚Äì2020)
        'Nico H√ºlkenberg': 13,          # 2010‚Äì2019, 2023‚Äì2025 (break: 2020‚Äì2022)
        'Max Verstappen': 11,           # 2015‚Äì2025
        'Charles Leclerc': 7,           # 2018‚Äì2025
        'Lando Norris': 7,              # 2019‚Äì2025
        'George Russell': 6,            # 2019‚Äì2025
        'Pierre Gasly': 8,              # 2017‚Äì2025
        'Esteban Ocon': 8,              # 2016, 2017‚Äì2018, 2020‚Äì2025 (missed 2019)
        'Lance Stroll': 8,              # 2017‚Äì2025
        'Yuki Tsunoda': 5,              # 2021‚Äì2025
        'Alex Albon': 5,                # 2019‚Äì2020, 2022‚Äì2025 (missed 2021)
        'Carlos Sainz': 11,             # 2015‚Äì2025
        'Oscar Piastri': 2,             # 2023‚Äì2025
        'Kimi Antonelli': 1,            # Debuted 2025
        'Oliver Bearman': 1,            # Partial 2024 debut, full season 2025
        'Jack Doohan': 1,               # Debuted 2025
        'Gabriel Bortoleto': 1,         # Debuted 2025
        'Isack Hadjar': 1,              # Debuted 2025
        'Liam Lawson': 2                # Partial 2023, full 2025 (missed 2024)
    }
    
    # Add experience for historical drivers with random values
    for driver in df['driver'].unique():
        if driver not in driver_experience:
            driver_experience[driver] = random.randint(1, 15)
    
    df['driver_experience'] = df['driver'].map(driver_experience)
    
    # Recent form (lower is better - average finishing position)
    df['recent_form'] = np.random.uniform(1, 20, len(df))
    
    # Qualifying gap to teammate
    df['quali_gap_to_teammate'] = np.random.uniform(-1.5, 1.5, len(df))
    
    return df

def add_constructor_features(df):
    """Add constructor performance features"""
    
    # 2024/2025 constructor standings
    constructor_standings = {
        'McLaren': 1, 'Ferrari': 2, 'Red Bull Racing': 3, 'Red Bull': 3,
        'Mercedes': 4, 'Aston Martin': 5, 'Alpine': 6, 'Haas F1 Team': 7, 'Haas': 7,
        'RB': 8, 'Williams': 9, 'Kick Sauber': 10, 'Sauber': 10
    }
    
    df['constructor_standing'] = df['constructor'].map(constructor_standings).fillna(10)
    df['budget_efficiency'] = np.random.uniform(0.7, 1.0, len(df))
    
    return df

def add_circuit_features(df):
    """Add circuit characteristics"""
    
    circuit_types = {
        'Monaco Circuit': 'Street',
        'Marina Bay Street Circuit': 'Street',
        'Baku City Circuit': 'Street',
        'Jeddah Corniche Circuit': 'Street',
        'Las Vegas Strip Circuit': 'Street',
        'Monza Circuit': 'Power',
        'Silverstone Circuit': 'Balanced',
        'Hungaroring': 'Twisty',
        'Circuit de Spa-Francorchamps': 'Power'
    }
    
    df['circuit_type'] = df['circuit'].map(circuit_types).fillna('Balanced')
    
    # Circuit characteristics
    df['drs_zones'] = df['circuit'].apply(lambda x: random.randint(1, 3))
    df['lap_length'] = df['circuit'].apply(lambda x: random.uniform(3.0, 7.0))
    df['safety_car_laps'] = np.random.poisson(3, len(df))
    df['avg_pit_time'] = np.random.uniform(2.0, 4.5, len(df))
    
    return df

def load_and_enhance_data():
    """Load and enhance F1 data"""
    
    # Try to load existing data
    data_files = ["data/f1_multi_year_results.csv", "data/f1_2023_results.csv"]
    df = None
    
    for file in data_files:
        if os.path.exists(file):
            print(f"üìä Loading data from {file}")
            df = pd.read_csv(file)
            break
    
    if df is None:
        print("‚ùå No data file found. Please run fetch_data.py first")
        return None
    
    print(f"üìà Loaded {len(df)} race results")
    
    # Clean data
    df = df.dropna(subset=['driver', 'constructor', 'circuit', 'grid', 'position'])
    df['grid'] = pd.to_numeric(df['grid'], errors='coerce')
    df['position'] = pd.to_numeric(df['position'], errors='coerce')
    
    # Remove invalid data
    df = df[(df['grid'] > 0) & (df['position'] > 0) & (df['position'] <= 20)]
    
    # Add weather if not present
    if 'weather' not in df.columns:
        df['weather'] = 'Dry'  # Default
        # Add some variety
        wet_circuits = ['Circuit de Spa-Francorchamps', 'Suzuka Circuit', 'Interlagos', 'Silverstone Circuit']
        df.loc[df['circuit'].isin(wet_circuits), 'weather'] = np.random.choice(['Wet', 'Mixed', 'Dry'], 
                                                                               size=len(df[df['circuit'].isin(wet_circuits)]),
                                                                               p=[0.2, 0.3, 0.5])
    
    # Add enhanced features
    df = enhance_weather_features(df)
    df = enhance_tire_strategy(df)
    df = add_driver_performance_features(df)
    df = add_constructor_features(df)
    df = add_circuit_features(df)
    
    print(f"‚úÖ Enhanced dataset with {len(df.columns)} features")
    return df

def train_enhanced_models():
    """Train enhanced ML models"""
    
    print("üöÄ Starting Enhanced F1 ML Training...")
    
    # Load and prepare data
    df = load_and_enhance_data()
    if df is None:
        return None
    
    # Create target variables
    df['podium'] = (df['position'] <= 3).astype(int)
    df['points_scored'] = (df['position'] <= 10).astype(int)
    df['winner'] = (df['position'] == 1).astype(int)
    
    # Encode categorical variables
    label_encoders = {}
    categorical_cols = ['driver', 'constructor', 'circuit', 'weather', 'tire_strategy', 'circuit_type']
    
    print("üîÑ Encoding categorical variables...")
    for col in categorical_cols:
        le = LabelEncoder()
        df[col + '_encoded'] = le.fit_transform(df[col].astype(str))
        label_encoders[col] = le
        print(f"   ‚Ä¢ {col}: {len(le.classes_)} unique values")
    
    # Define feature set
    enhanced_features = [
        'grid', 'constructor_encoded', 'circuit_encoded', 'driver_encoded', 
        'weather_encoded', 'tire_strategy_encoded', 'temperature', 'humidity',
        'wind_speed', 'track_temp', 'driver_experience', 'recent_form',
        'quali_gap_to_teammate', 'constructor_standing', 'budget_efficiency',
        'circuit_type_encoded', 'drs_zones', 'lap_length', 'safety_car_laps',
        'avg_pit_time'
    ]
    
    X = df[enhanced_features]
    
    # Scale numerical features
    numerical_features = [
        'temperature', 'humidity', 'wind_speed', 'track_temp', 
        'driver_experience', 'recent_form', 'quali_gap_to_teammate',
        'budget_efficiency', 'lap_length', 'avg_pit_time'
    ]
    
    scaler = StandardScaler()
    X_scaled = X.copy()
    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])
    
    models = {}
    
    print("\nüéØ Training Models...")
    
    # 1. Position Prediction (Regression)
    print("   üìç Training Position Prediction Model...")
    y_pos = df['position']
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_pos, test_size=0.2, random_state=42)
    
    # Try both RandomForest and GradientBoosting
    models_to_try = {
        'RandomForest': RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1),
        'GradientBoosting': GradientBoostingRegressor(n_estimators=200, max_depth=8, random_state=42)
    }
    
    best_model = None
    best_score = float('inf')
    
    for name, model in models_to_try.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        print(f"      {name} - RMSE: {rmse:.3f}, MAE: {mae:.3f}")
        
        if rmse < best_score:
            best_score = rmse
            best_model = model
    
    models['position'] = best_model
    print(f"      ‚úÖ Best Position Model: RMSE {best_score:.3f}")
    
    # 2. Podium Prediction
    print("   ü•â Training Podium Prediction Model...")
    y_podium = df['podium']
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_podium, test_size=0.2, random_state=42)
    
    clf_podium = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)
    clf_podium.fit(X_train, y_train)
    y_pred = clf_podium.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    print(f"      ‚úÖ Podium Accuracy: {accuracy:.3f}")
    models['podium'] = clf_podium
    
    # 3. Points Scoring Prediction
    print("   üèÅ Training Points Prediction Model...")
    y_points = df['points_scored']
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_points, test_size=0.2, random_state=42)
    
    clf_points = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, n_jobs=-1)
    clf_points.fit(X_train, y_train)
    y_pred = clf_points.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    print(f"      ‚úÖ Points Accuracy: {accuracy:.3f}")
    models['points'] = clf_points
    
    # 4. Winner Prediction (if enough data)
    winners_df = df[df['winner'] == 1]
    print(f"   üèÜ Training Winner Prediction Model ({len(winners_df)} winners)...")
    
    if len(winners_df) > 50:
        y_winner = df['winner']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_winner, test_size=0.2, random_state=42)
        
        clf_winner = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, 
                                          class_weight='balanced', n_jobs=-1)
        clf_winner.fit(X_train, y_train)
        y_pred = clf_winner.predict(X_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        print(f"      ‚úÖ Winner Accuracy: {accuracy:.3f}")
        models['winner'] = clf_winner
    else:
        print("      ‚ö†Ô∏è Insufficient winner data, skipping winner model")
        models['winner'] = None
    
    # Save models
    print("\nüíæ Saving Models...")
    for name, model in models.items():
        if model is not None:
            filename = f"models/{name}_enhanced_model.pkl"
            joblib.dump(model, filename)
            print(f"   ‚úÖ Saved {filename}")
    
    joblib.dump(label_encoders, "models/enhanced_label_encoders.pkl")
    joblib.dump(scaler, "models/feature_scaler.pkl")
    joblib.dump(enhanced_features, "models/feature_names.pkl")
    
    # Feature importance analysis
    print("\nüìä Feature Importance Analysis:")
    if models['position']:
        feature_importance = pd.DataFrame({
            'feature': enhanced_features,
            'importance': models['position'].feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("Top 10 Most Important Features:")
        for i, row in feature_importance.head(10).iterrows():
            print(f"   {row['feature']}: {row['importance']:.4f}")
    
    # Model performance summary
    print("\nüéâ Training Complete!")
    print("=" * 50)
    print("Enhanced F1 ML Models Successfully Trained")
    print(f"Dataset Size: {len(df):,} race results")
    print(f"Features: {len(enhanced_features)} enhanced features")
    print(f"Models Trained: {len([m for m in models.values() if m is not None])}")
    print("=" * 50)
    
    # Save training log
    training_log = {
        'timestamp': datetime.now().isoformat(),
        'dataset_size': len(df),
        'features': len(enhanced_features),
        'models_trained': len([m for m in models.values() if m is not None]),
        'position_rmse': best_score,
        'podium_accuracy': accuracy_score(y_test, clf_podium.predict(X_test)),
        'points_accuracy': accuracy_score(y_test, clf_points.predict(X_test))
    }
    
    log_df = pd.DataFrame([training_log])
    log_df.to_csv("logs/training_log.csv", mode='a', header=not os.path.exists("logs/training_log.csv"), index=False)
    
    return models, label_encoders, scaler, enhanced_features

if __name__ == "__main__":
    # Set random seeds for reproducibility
    np.random.seed(42)
    random.seed(42)
    
    try:
        # Run the enhanced training
        results = train_enhanced_models()
        
        if results:
            models, label_encoders, scaler, features = results
            
            # Test prediction functionality
            print("\nüß™ Testing Prediction Functionality...")
            
            # Create a sample prediction
            sample_features = [
                1,  # grid
                0,  # constructor_encoded
                0,  # circuit_encoded  
                0,  # driver_encoded
                0,  # weather_encoded
                0,  # tire_strategy_encoded
                25, # temperature
                45, # humidity
                5,  # wind_speed
                40, # track_temp
                10, # driver_experience
                3,  # recent_form
                -0.2, # quali_gap
                1,  # constructor_standing
                0.95, # budget_efficiency
                0,  # circuit_type_encoded
                2,  # drs_zones
                5.5, # lap_length
                2,  # safety_car_laps
                3.2  # avg_pit_time
            ]
            
            # Scale the sample
            sample_array = np.array(sample_features).reshape(1, -1)
            numerical_indices = [6, 7, 8, 9, 10, 11, 12, 15, 17, 19]
            sample_scaled = sample_array.copy()
            sample_scaled[:, numerical_indices] = scaler.transform(sample_array[:, numerical_indices])
            
            # Test predictions
            if models['position']:
                pos_pred = models['position'].predict(sample_scaled)[0]
                print(f"   üìç Sample Position Prediction: {pos_pred:.1f}")
            
            if models['podium']:
                podium_pred = models['podium'].predict(sample_scaled)[0]
                print(f"   ü•â Sample Podium Prediction: {'Yes' if podium_pred else 'No'}")
            
            if models['points']:
                points_pred = models['points'].predict(sample_scaled)[0]
                print(f"   üèÅ Sample Points Prediction: {'Yes' if points_pred else 'No'}")
            
            print("\n‚úÖ All tests passed! Models are ready for production.")
            print("\nüöÄ To use the models:")
            print("   1. Start the Flask API: python app.py")
            print("   2. Access predictions at http://localhost:5059/api/predict")
            print("   3. Check model status at http://localhost:5059/api/health")
            
        else:
            print("‚ùå Training failed. Please check the error messages above.")
            
    except Exception as e:
        print(f"‚ùå Training failed with error: {e}")
        print("\nüîß Troubleshooting steps:")
        print("   1. Ensure you have run fetch_data.py to generate training data")
        print("   2. Check that data/f1_multi_year_results.csv exists")
        print("   3. Verify all required packages are installed:")
        print("      pip install pandas scikit-learn joblib numpy")
        print("   4. Check the logs/ folder for detailed error information")
        
        import traceback
        print(f"\nüìã Full error traceback:")
        traceback.print_exc()